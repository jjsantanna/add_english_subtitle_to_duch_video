{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "653c3000-d03f-4227-be8f-9848116c89fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_KEY = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d6e220-4690-4ecf-bb5b-bebe3a1fdcb0",
   "metadata": {},
   "source": [
    "# Transcribing, Translating, and Adding English Subtitle to a Dutch Video\n",
    "\n",
    "1. Video format check/conversion (.webm to .mp4) \"what the fuck is .wedm?\" (library ffmpeg)\n",
    "2. Video-to-audio (.webm to .mp3) (library moviepy)\n",
    "3. Audio-to-text (.str output) (library whisper)\n",
    "4. Text translation (.str output) (Azure OpenAI gpt4)\n",
    "5. MANUALLY checking the result by playing it using VLC (and manually fixing mistakes)\n",
    "6. Improving the subtitle text style (converting from .srt to .ass)\n",
    "8. Adding the translated subtitle to the video "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e2819-292c-4638-9624-75e83dfcf66c",
   "metadata": {},
   "source": [
    "# .webm to .mp4 (video + audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9b2ad5-55a4-49a9-b4e2-7f9b52d0bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa53b58-8bef-406c-99f5-ad7086602e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "# Path to the input .webm file\n",
    "input_file = \"Microsoft PotY speech for Northwave.webm\"\n",
    "\n",
    "# Path to the output .mp4 file\n",
    "output_file = \"Microsoft PotY speech for Northwave.mp4\"\n",
    "\n",
    "# Perform the conversion\n",
    "(\n",
    "    ffmpeg\n",
    "    .input(input_file)\n",
    "    .output(output_file, vcodec='libx264', acodec='aac')\n",
    "    .run(overwrite_output=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e9fad2-dcea-4258-8e32-3004921bdeef",
   "metadata": {},
   "source": [
    "# Video-to-audio (.webm to .mp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63326ea-3ad3-4f65-85bd-969559b5dd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108cca60-9b1a-4b4c-9556-1437737a0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "input_file = \"Microsoft PotY speech for Northwave.webm\"\n",
    "output_file = \"Microsoft PotY speech for Northwave.mp3\"\n",
    "\n",
    "video = VideoFileClip(input_file)\n",
    "audio = video.audio\n",
    "audio.write_audiofile(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137986cd-d3d7-4246-b837-c11518ea74d5",
   "metadata": {},
   "source": [
    "# text-to-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb45b999-184a-46ed-a38d-5c7ec86f1d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import playsound\n",
    "import os\n",
    "\n",
    "def text2speech(text,lang):\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    filename = \"temp.mp3\"\n",
    "    tts.save(filename)\n",
    "    playsound.playsound(filename)\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b98dd1b-de1f-46f7-8add-c1f0963117b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Goedemorgen. Het testen van de tekst naar spraak en de spraak naar transcriptie.\"\n",
    "lang = \"nl\"\n",
    "text2speech(text,lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e60afcd-9509-44f0-bb8e-77fc2ed4292a",
   "metadata": {},
   "source": [
    "# text-to-speech_mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2696e201-4b40-4528-bfc8-7dbb22467cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "\n",
    "def text2mp3(text, lang, output_filename=\"output.mp3\"):\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    tts.save(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a495ebba-d867-4b3a-80c2-5b20819be263",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Goedemorgen. Het testen van de tekst naar spraak en de spraak naar transcriptie.\"\n",
    "lang = 'nl'\n",
    "output_filename = \"output.mp3\"\n",
    "text2mp3(text, lang, output_filename=\"output.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67518557-08d7-4658-97a0-62d7a28cace0",
   "metadata": {},
   "source": [
    "# speech-to-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db3228d-18da-4541-a9ce-5048faefddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da53f63c-738e-4d52-a9e5-53ef35a1d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be59a529-42e1-4fc4-bc66-b749121bb732",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"output.mp3\"\n",
    "result = model.transcribe(audio_path, language='nl')\n",
    "result['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f40843-87ea-4f5d-9205-3047be92fe72",
   "metadata": {},
   "source": [
    "# audio-to-text .srt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7c0c31-6200-445a-a31b-0762b437754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import datetime\n",
    "\n",
    "# Load the Whisper model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Path to the audio file\n",
    "audio_path = \"Microsoft PotY speech for Northwave.mp3\"\n",
    "\n",
    "# Transcribe the audio file\n",
    "result = model.transcribe(audio_path, language='nl')\n",
    "\n",
    "# Function to format time in SRT time format\n",
    "def format_timestamp(seconds):\n",
    "    ms = int((seconds % 1) * 1000)\n",
    "    seconds = int(seconds)\n",
    "    hrs = seconds // 3600\n",
    "    mins = (seconds % 3600) // 60\n",
    "    secs = seconds % 60\n",
    "    return f\"{hrs:02}:{mins:02}:{secs:02},{ms:03}\"\n",
    "\n",
    "# Open a file to write the SRT output\n",
    "with open(\"output.srt\", \"w\", encoding=\"utf-8\") as srt_file:\n",
    "    for i, segment in enumerate(result['segments']):\n",
    "        start_time = format_timestamp(segment['start'])\n",
    "        end_time = format_timestamp(segment['end'])\n",
    "        text = segment['text']\n",
    "        \n",
    "        # Write the SRT entry\n",
    "        srt_file.write(f\"{i + 1}\\n\")\n",
    "        srt_file.write(f\"{start_time} --> {end_time}\\n\")\n",
    "        srt_file.write(f\"{text}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835b0f2b-cac0-4d23-b1d9-849e58d45872",
   "metadata": {},
   "source": [
    "# Convert an .srt file from Dutch to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c76b8f2-c2ce-448d-b6e4-2798beafb3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d4fe55-a4b0-494f-a4e8-5c0b454f757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import time\n",
    "\n",
    "def azureopenai_gpt4_1106(OPENAI_KEY, system_prompt, input_message):\n",
    "    client = AzureOpenAI(azure_endpoint=\"https://instance-openai-france.openai.azure.com/\",\n",
    "                         api_key=OPENAI_KEY,  \n",
    "                         api_version=\"2024-02-15-preview\")\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt4-1106\",  # model = \"deployment_name\"\n",
    "            messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                      {\"role\": \"user\", \"content\": input_message}]\n",
    "        )\n",
    "        output = response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        output = {'error': str(e)}\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add36aa5-2602-4192-bb82-ac66cb58d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_srt_file(input_srt_path, output_srt_path, openai_key):\n",
    "    # Read the .srt file\n",
    "    with open(input_srt_path, 'r', encoding='utf-8') as file:\n",
    "        srt_content = file.read()\n",
    "\n",
    "    # Define the system prompt for translation\n",
    "    system_prompt = \"Translate the following Dutch subtitles to English:\"\n",
    "\n",
    "    # Translate the .srt content\n",
    "    response = azureopenai_gpt4_1106(openai_key, system_prompt, srt_content)\n",
    "\n",
    "    if 'error' in response:\n",
    "        print(f\"Error: {response['error']}\")\n",
    "        return\n",
    "    \n",
    "    translated_content = response\n",
    "\n",
    "    # Write the translated content to a new .srt file\n",
    "    with open(output_srt_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(translated_content)\n",
    "\n",
    "    print(f\"Translated .srt file has been saved as {output_srt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df93c9-fbc3-4a41-a734-2eb16d2c8fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_srt_path = \"Microsoft PotY speech for Northwave_nl.srt\"\n",
    "output_srt_path = \"Microsoft PotY speech for Northwave_en.srt\"\n",
    "\n",
    "translate_srt_file(input_srt_path, output_srt_path, OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f762d125-4764-41c9-982b-ae728bc4e507",
   "metadata": {},
   "source": [
    "# Convert from .srt to .ass (for a better subtitle formating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a679146c-01f9-4737-b5e4-530120573f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pysubs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34d8266-2863-4285-b134-7064b946c417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysubs2\n",
    "\n",
    "def hex_to_rgb(hex_color):\n",
    "    hex_color = hex_color.lstrip('&H').lstrip('#')\n",
    "    return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "def convert_srt_to_ass(srt_path, ass_path, font_name=\"Roboto\", font_size=24, primary_color=\"&H00FFFFFF\", outline_color=\"&H00000000\", back_color=\"&H64000000\"):\n",
    "    subs = pysubs2.load(srt_path, encoding=\"utf-8\")\n",
    "    \n",
    "    # Define styles\n",
    "    style = pysubs2.SSAStyle()\n",
    "    style.fontname = font_name\n",
    "    style.fontsize = font_size\n",
    "    style.primarycolor = pysubs2.Color(*hex_to_rgb(primary_color))\n",
    "    style.outlinecolor = pysubs2.Color(*hex_to_rgb(outline_color))\n",
    "    style.backcolor = pysubs2.Color(*hex_to_rgb(back_color))\n",
    "    style.bold = -1\n",
    "    style.shadow = 2\n",
    "    style.outline = 1\n",
    "    style.alignment = pysubs2.Alignment.BOTTOM_CENTER\n",
    "    style.marginl = 10\n",
    "    style.marginr = 10\n",
    "    style.marginv = 10\n",
    "\n",
    "    subs.styles[\"Default\"] = style\n",
    "    \n",
    "    subs.save(ass_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d582a500-fb86-4268-9c77-e92d7a3cd046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "srt_path = 'Microsoft PotY speech for Northwave_en_v3.srt'\n",
    "ass_path = 'Microsoft PotY speech for Northwave_en_v3.ass'\n",
    "\n",
    "convert_srt_to_ass(srt_path, ass_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a256297e-1e45-4d26-bc77-3b5a7e468a9c",
   "metadata": {},
   "source": [
    "# Add subtitle to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0328ae91-d039-40ba-b6b1-e86a6d37b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "def add_subtitle(video_path, subtitle_path, output_path):\n",
    "    (\n",
    "        ffmpeg\n",
    "        .input(video_path)\n",
    "        .output(output_path, vf=f\"subtitles={subtitle_path}\")\n",
    "        .run(overwrite_output=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1d4965-5831-47a3-af48-86dfc982f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "video_path = 'Microsoft PotY speech for Northwave.mp4'\n",
    "subtitle_path = 'Microsoft PotY speech for Northwave_en_v3.ass'\n",
    "output_path = 'Microsoft PotY speech for Northwave_EN_v2.mp4'\n",
    "\n",
    "add_subtitle(video_path, subtitle_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1411ba6-9d10-4999-b8ed-12a0de4665f0",
   "metadata": {},
   "source": [
    "# MERGING EVERYTHING!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c06281e2-82e4-4f81-9d51-708ea9a889a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "from moviepy.editor import VideoFileClip\n",
    "import whisper\n",
    "import datetime\n",
    "from openai import AzureOpenAI\n",
    "import time\n",
    "import pysubs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6357205-a3b7-4c9a-b580-529fdad4ff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"Microsoft PotY speech for Northwave.webm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e20a9158-9484-4d94-abdd-8edc5d27ce61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Converting .webm to .mp4 (video to video)\n",
      "- Extracting only the audio from the original video\n",
      "- Converting speech-to-text (in the original format, Dutch)\n",
      "- Translating the text in the .str from Dutch to English using Azure OpenAI\n",
      "- Converting the .str to .ass for a better formating of the subtitle\n",
      "- Adding the final translated subtitle with nice style to video\n"
     ]
    }
   ],
   "source": [
    "### Converting .webm to .mp4 (video to video)\n",
    "print(\"- Converting .webm to .mp4 (video to video)\")\n",
    "video_mp4 = input_file.split('.')[0]+'.mp4'\n",
    "(\n",
    "    ffmpeg\n",
    "    .input(input_file)\n",
    "    .output(video_mp4, vcodec='libx264', acodec='aac')\n",
    "    .run(overwrite_output=True, quiet=True)\n",
    ")\n",
    "\n",
    "### Extracting only the audio from the original video\n",
    "print(\"- Extracting only the audio from the original video\")\n",
    "audio_path = input_file.split('.')[0]+'.mp3'\n",
    "video = VideoFileClip(input_file)\n",
    "audio = video.audio\n",
    "audio.write_audiofile(audio_path, verbose=False, logger=None)\n",
    "\n",
    "### Converting speech-to-text (in the original format, Dutch)\n",
    "print(\"- Converting speech-to-text (in the original format, Dutch)\")\n",
    "model = whisper.load_model(\"base\")\n",
    "result = model.transcribe(audio_path, language='nl')\n",
    "\n",
    "# Function to format time in SRT time format\n",
    "def format_timestamp(seconds):\n",
    "    ms = int((seconds % 1) * 1000)\n",
    "    seconds = int(seconds)\n",
    "    hrs = seconds // 3600\n",
    "    mins = (seconds % 3600) // 60\n",
    "    secs = seconds % 60\n",
    "    return f\"{hrs:02}:{mins:02}:{secs:02},{ms:03}\"\n",
    "\n",
    "subtitle_nl = input_file.split('.')[0]+'_NL.str'\n",
    "with open(subtitle_nl, \"w\", encoding=\"utf-8\") as srt_file:\n",
    "    for i, segment in enumerate(result['segments']):\n",
    "        start_time = format_timestamp(segment['start'])\n",
    "        end_time = format_timestamp(segment['end'])\n",
    "        text = segment['text']\n",
    "        \n",
    "        # Write the SRT entry\n",
    "        srt_file.write(f\"{i + 1}\\n\")\n",
    "        srt_file.write(f\"{start_time} --> {end_time}\\n\")\n",
    "        srt_file.write(f\"{text}\\n\\n\")\n",
    "\n",
    "### Translating the text in the .str from Dutch to English using Azure OpenAI\n",
    "print(\"- Translating the text in the .str from Dutch to English using Azure OpenAI\")\n",
    "def azureopenai_gpt4_1106(OPENAI_KEY, system_prompt, input_message):\n",
    "    client = AzureOpenAI(azure_endpoint=\"https://instance-openai-france.openai.azure.com/\",\n",
    "                         api_key=OPENAI_KEY,  \n",
    "                         api_version=\"2024-02-15-preview\")\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt4-1106\",  # model = \"deployment_name\"\n",
    "            messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                      {\"role\": \"user\", \"content\": input_message}]\n",
    "        )\n",
    "        output = response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        output = {'error': str(e)}\n",
    "\n",
    "    return output\n",
    "\n",
    "def translate_srt_file(input_srt_path, output_srt_path, openai_key):\n",
    "    # Read the .srt file\n",
    "    with open(input_srt_path, 'r', encoding='utf-8') as file:\n",
    "        srt_content = file.read()\n",
    "\n",
    "    # Define the system prompt for translation\n",
    "    system_prompt = \"Translate the following Dutch subtitles to English:\"\n",
    "\n",
    "    # Translate the .srt content\n",
    "    response = azureopenai_gpt4_1106(openai_key, system_prompt, srt_content)\n",
    "\n",
    "    if 'error' in response:\n",
    "        print(f\"Error: {response['error']}\")\n",
    "        return\n",
    "    \n",
    "    translated_content = response\n",
    "\n",
    "    # Write the translated content to a new .srt file\n",
    "    with open(output_srt_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(translated_content)\n",
    "\n",
    "subtitle_en = input_file.split('.')[0]+'_EN.str'\n",
    "translate_srt_file(subtitle_nl, subtitle_en, OPENAI_KEY)\n",
    "\n",
    "################\n",
    "### MANUAL STEP TO VALIDATE AND FIX THE translated to English subtitle\n",
    "###############\n",
    "\n",
    "### Converting the .str to .ass for a better formating of the subtitle\n",
    "print(\"- Converting the .str to .ass for a better formating of the subtitle\")\n",
    "def hex_to_rgb(hex_color):\n",
    "    hex_color = hex_color.lstrip('&H').lstrip('#')\n",
    "    return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "def convert_srt_to_ass(srt_path, ass_path, font_name=\"Roboto\", font_size=24, primary_color=\"&H00FFFFFF\", outline_color=\"&H00000000\", back_color=\"&H64000000\"):\n",
    "    subs = pysubs2.load(srt_path, encoding=\"utf-8\")\n",
    "    \n",
    "    # Define styles\n",
    "    style = pysubs2.SSAStyle()\n",
    "    style.fontname = font_name\n",
    "    style.fontsize = font_size\n",
    "    style.primarycolor = pysubs2.Color(*hex_to_rgb(primary_color))\n",
    "    style.outlinecolor = pysubs2.Color(*hex_to_rgb(outline_color))\n",
    "    style.backcolor = pysubs2.Color(*hex_to_rgb(back_color))\n",
    "    style.bold = -1\n",
    "    style.shadow = 2\n",
    "    style.outline = 1\n",
    "    style.alignment = pysubs2.Alignment.BOTTOM_CENTER\n",
    "    style.marginl = 10\n",
    "    style.marginr = 10\n",
    "    style.marginv = 10\n",
    "\n",
    "    subs.styles[\"Default\"] = style\n",
    "    \n",
    "    subs.save(ass_path)\n",
    "\n",
    "subtitle_en_ass = input_file.split('.')[0]+'_EN.ass'\n",
    "\n",
    "convert_srt_to_ass(subtitle_en, subtitle_en_ass)\n",
    "\n",
    "### Adding the final translated subtitle with nice style to video\n",
    "print(\"- Adding the final translated subtitle with nice style to video\")\n",
    "def add_subtitle(video_path, subtitle_path, output_path):\n",
    "    (\n",
    "        ffmpeg\n",
    "        .input(video_path)\n",
    "        .output(output_path, vf=f\"subtitles={subtitle_path}\")\n",
    "        .run(overwrite_output=True, quiet=True)\n",
    "    )\n",
    "\n",
    "final_video = input_file.split('.')[0]+'_EN.mp4'\n",
    "add_subtitle(video_mp4, subtitle_en_ass, final_video)\n",
    "\n",
    "print(\"CONGRATULATIONS!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f64b0be-fc2a-4b28-b56e-de977953eb98",
   "metadata": {},
   "source": [
    "# In case there is a better version of the .srt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfb29a1d-6f3a-415d-8fc9-e976cd2116cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONGRATULATIONS!\n"
     ]
    }
   ],
   "source": [
    "subtitle_en_improved = \"Microsoft PotY speech for Northwave_EN_v2.str\"\n",
    "\n",
    "### Convert from .str to .ass\n",
    "subtitle_en_ass = subtitle_en_improved.split('.')[0]+'.ass'\n",
    "convert_srt_to_ass(subtitle_en_improved, subtitle_en_ass)\n",
    "\n",
    "### Adding the final translated subtitle with nice style to video\n",
    "final_video = subtitle_en_improved.split('.')[0]+'.mp4'\n",
    "add_subtitle(video_mp4, subtitle_en_ass, final_video)\n",
    "\n",
    "print(\"CONGRATULATIONS!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
